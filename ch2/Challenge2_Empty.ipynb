{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e593dc2",
   "metadata": {},
   "source": [
    "# Optimizing the Python Code for Big Data \n",
    "Balancing Coding Complexity against Computational Complexity \n",
    "    \n",
    "    AUTHOR: Dr. Roy Jafari \n",
    "\n",
    "\n",
    "# Chapter 2: Choosing the right data types "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b31afdc",
   "metadata": {},
   "source": [
    "## Challenge 2: int8, int16, int32, or int64?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "254a78a3",
   "metadata": {},
   "source": [
    "At the end of this challenge, we will have gained experience on when and where, and which of the four integer types int8, int16, int32, or int64 must be used. \n",
    "Use the following prompts to complete this challenge.\n",
    "1.\tThe following code creates four pandas DataFrames from the one DataFrame `person_df`. The `person_df` DataFrame has two columns - `Height` and `Weight` – and 100 million rows. The DataFrame `person_df` is filled up randomly, and using the function `np.random.normal()` the code makes sure that the random values are generated within the reasonable range that we would expect for the values of weight and height. The chosen units of measurement for weight and height are Kilograms and Centimeters. After the generation of `person_df` is completed the four DataFrames are created from `persond_df`, and they are kept in the dictionary `dfs`. The difference between these DataFrames is their data type; these DataFrames have data types of *int8*, *int16*, *int32*, and *int64*, respectively. Run the code, and go to the next step. Pay attention the code might take a few seconds to complete.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59189b5b",
   "metadata": {},
   "source": [
    "```\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "n = 10**8\n",
    "person_df = pd.DataFrame(\n",
    "    index=range(n),\n",
    "    columns=['Height','Weight']\n",
    ")\n",
    "person_df.Height = np.random.normal(178,10,n)\n",
    "person_df.Weight = np.random.normal(83,7,n)\n",
    "\n",
    "int_bits = ['8','16','32','64']\n",
    "dfs = {}\n",
    "for int_bit in int_bits:\n",
    "    type_name = f'int{int_bit}'\n",
    "    dfs[type_name] = person_df.astype(type_name)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67109bc5",
   "metadata": {},
   "source": [
    "2.\tThe following code access each of the four DataFrames in `dfs` and run their `.info()` property. Run and study the outputs of the code. Is There a significant difference in the amount of memory these four DataFrames use? If yes, what accounts for the significant difference? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4dca594",
   "metadata": {},
   "source": [
    "```\n",
    "for df in dfs.values():\n",
    "    df.info()\n",
    "    print('\\r\\n')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3ad59b",
   "metadata": {},
   "source": [
    "**Answer**: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b344e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7f244921",
   "metadata": {},
   "source": [
    "3.\tThe values in one of the DataFrames are corrupted. Use the following code to print out the values of all the DataFrames, and figure out which one is corrupted. Investigate to figure out what caused the corruption."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d839db",
   "metadata": {},
   "source": [
    "```\n",
    "for key,df in dfs.items():\n",
    "    print(key)\n",
    "    print(df)\n",
    "    print('\\r\\n')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f2fbf0",
   "metadata": {},
   "source": [
    "**Answer**: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a63e9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d8a163f8",
   "metadata": {},
   "source": [
    "4.\tThe following code performs a computational experiment to see if the runtime of performing big data manipulations changes when our data is encoded in *int8*, *int16*, *int32*, or *int64*. The code attempts to calculate the **Body Mass Index (BMI)** which is a health metric calculated from the height and weight of an individual. The formula for BMI is weight in Kilograms divided by the square of the height in Meters. Run the following code and study its outcome."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2610fad1",
   "metadata": {},
   "source": [
    "```\n",
    "import time\n",
    "exp1_df = pd.DataFrame(\n",
    "    index = dfs.keys(),\n",
    "    columns=['RunTime']\n",
    ")\n",
    "for key in dfs.keys():\n",
    "    wdf = dfs[key]\n",
    "    t0 = time.time()\n",
    "    wdf['BMI'] = wdf.Weight/((wdf.Height/100)**2)\n",
    "    exp1_df.at[key,'RunTime'] = time.time()-t0\n",
    "print(exp1_df)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f3f48a",
   "metadata": {},
   "source": [
    "5.\tWeren’t you expecting to see an increasing `RunTime` when we move from *int8* to *in64*? However, that’s not what happens when you run the code. What do you think is the reason? If you are having a hard time coming to an answer, study and run the following code, it will give you a hint. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88ba864",
   "metadata": {},
   "source": [
    "```\n",
    "for df in dfs.values():\n",
    "    df.info()\n",
    "    print('\\r\\n--DIVIDE--\\r\\n')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45036e9",
   "metadata": {},
   "source": [
    "**Answer**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff50de34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7aeff0a4",
   "metadata": {},
   "source": [
    "6.\tThe following code runs another experiment. Once you run the experiment you will see that when we move from int8 to in64 the RunTime also increases. Study the code, and figure out what’s different in this code that matches our expectations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7294e5ee",
   "metadata": {},
   "source": [
    "```\n",
    "exp2_df = pd.DataFrame(\n",
    "    index = dfs.keys(),\n",
    "    columns=['RunTime']\n",
    ")\n",
    "for key in dfs.keys():\n",
    "    wdf = dfs[key]\n",
    "    t0 = time.time()\n",
    "    wdf['Some Calculation'] = wdf.Weight+(wdf.Height**2)\n",
    "    exp2_df.at[key,'RunTime'] = time.time()-t0\n",
    "print(exp2_df)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46259e8f",
   "metadata": {},
   "source": [
    "**Answer**: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069f1f68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e97f5c57",
   "metadata": {},
   "source": [
    "7.\tIf you are having trouble answering the question in the preceding step, running the following code will give you an important hint."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1434c64b",
   "metadata": {},
   "source": [
    "```\n",
    "for df in dfs.values():\n",
    "    df.info()\n",
    "    print('\\r\\n--DIVIDE--\\r\\n')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421b94bd",
   "metadata": {},
   "source": [
    "**Answer**: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b673a7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3bd3df78",
   "metadata": {},
   "source": [
    "8.\tFrom what you experienced, formulate an answer to the following question: if we are aiming to use the lightest-weight-possible integer data type between *int8*, *int16*, *int32*, and *int64*, how can we make sure that our data will not get corrupted similar to what we experienced in step 2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43172132",
   "metadata": {},
   "source": [
    "**Answer**: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1e7aa6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7922a2f6",
   "metadata": {},
   "source": [
    "9.\tFrom what you experienced, formulate an answer to the following question: in what situations choosing the lightest-weight-possible integer data type will for sure lead to less CPU usage?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4482154d",
   "metadata": {},
   "source": [
    "**Answer**: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c74235",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
