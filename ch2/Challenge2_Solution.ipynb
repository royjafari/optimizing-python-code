{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e593dc2",
   "metadata": {},
   "source": [
    "# Optimizing the Python Code for Big Data \n",
    "Balancing Coding Complexity against Computational Complexity \n",
    "    \n",
    "    AUTHOR: Dr. Roy Jafari \n",
    "\n",
    "\n",
    "# Chapter 2: Choosing the right data types "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b31afdc",
   "metadata": {},
   "source": [
    "## Challenge 2: int8, int16, int32, or int64?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "254a78a3",
   "metadata": {},
   "source": [
    "At the end of this challenge, we will have gained experience on when and where, and which of the four integer types int8, int16, int32, or int64 must be used. \n",
    "Use the following prompts to complete this challenge.\n",
    "1.\tThe following code creates four pandas DataFrames from the one DataFrame `person_df`. The `person_df` DataFrame has two columns - `Height` and `Weight` – and 100 million rows. The DataFrame `person_df` is filled up randomly, and using the function `np.random.normal()` the code makes sure that the random values are generated within the reasonable range that we would expect for the values of weight and height. The chosen units of measurement for weight and height are Kilograms and Centimeters. After the generation of `person_df` is completed the four DataFrames are created from `persond_df`, and they are kept in the dictionary `dfs`. The difference between these DataFrames is their data type; these DataFrames have data types of *int8*, *int16*, *int32*, and *int64*, respectively. Run the code, and go to the next step. Pay attention the code might take a few seconds to complete.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d438e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "n = 10**8\n",
    "person_df = pd.DataFrame(\n",
    "    index=range(n),\n",
    "    columns=['Height','Weight']\n",
    ")\n",
    "person_df.Height = np.random.normal(178,10,n)\n",
    "person_df.Weight = np.random.normal(83,7,n)\n",
    "\n",
    "int_bits = ['8','16','32','64']\n",
    "dfs = {}\n",
    "for int_bit in int_bits:\n",
    "    type_name = f'int{int_bit}'\n",
    "    dfs[type_name] = person_df.astype(type_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67109bc5",
   "metadata": {},
   "source": [
    "2.\tThe following code access each of the four DataFrames in `dfs` and run their `.info()` property. Run and study the outputs of the code. Is There a significant difference in the amount of memory these four DataFrames use? If yes, what accounts for the significant difference? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33a0beb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000000 entries, 0 to 99999999\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Dtype\n",
      "---  ------  -----\n",
      " 0   Height  int8 \n",
      " 1   Weight  int8 \n",
      "dtypes: int8(2)\n",
      "memory usage: 190.7 MB\n",
      "\r\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000000 entries, 0 to 99999999\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Dtype\n",
      "---  ------  -----\n",
      " 0   Height  int16\n",
      " 1   Weight  int16\n",
      "dtypes: int16(2)\n",
      "memory usage: 381.5 MB\n",
      "\r\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000000 entries, 0 to 99999999\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Dtype\n",
      "---  ------  -----\n",
      " 0   Height  int32\n",
      " 1   Weight  int32\n",
      "dtypes: int32(2)\n",
      "memory usage: 762.9 MB\n",
      "\r\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000000 entries, 0 to 99999999\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Dtype\n",
      "---  ------  -----\n",
      " 0   Height  int64\n",
      " 1   Weight  int64\n",
      "dtypes: int64(2)\n",
      "memory usage: 1.5 GB\n",
      "\r\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for df in dfs.values():\n",
    "    df.info()\n",
    "    print('\\r\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3ad59b",
   "metadata": {},
   "source": [
    "**Answer**: Yes, there is a significant difference between them in terms of memory usage. The following list of their usages:\n",
    "\n",
    "- *int8*: 190.7 MB\n",
    "- *int16*: 381.5 MB\n",
    "- *int32*: 762.9 MB\n",
    "- *int64*: 1.5 GM\n",
    "\n",
    "If you notice the amount of data usage doubles as we move from *int8* to *int16*, from *int16* to *int32*, and from *int32* to *int64*. \n",
    "\n",
    "The reason for these changes is the amount of memory pandas put aside for each type of integer. pandas put aside 1, 2, 4, and 8 bytes respectively for *int8*, *int16*, *int32*, and *int64*.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f244921",
   "metadata": {},
   "source": [
    "3.\tThe values in one of the DataFrames are corrupted. Use the following code to print out the values of all the DataFrames, and figure out which one is corrupted. Investigate to figure out what caused the corruption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "afabe3c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int8\n",
      "          Height  Weight\n",
      "0            -95      88\n",
      "1            -81      75\n",
      "2            -51      70\n",
      "3            -75      83\n",
      "4            -79      80\n",
      "...          ...     ...\n",
      "99999995     -66      86\n",
      "99999996     -85      81\n",
      "99999997     -74      80\n",
      "99999998     -87      80\n",
      "99999999     -82      68\n",
      "\n",
      "[100000000 rows x 2 columns]\n",
      "\r\n",
      "\n",
      "int16\n",
      "          Height  Weight\n",
      "0            161      88\n",
      "1            175      75\n",
      "2            205      70\n",
      "3            181      83\n",
      "4            177      80\n",
      "...          ...     ...\n",
      "99999995     190      86\n",
      "99999996     171      81\n",
      "99999997     182      80\n",
      "99999998     169      80\n",
      "99999999     174      68\n",
      "\n",
      "[100000000 rows x 2 columns]\n",
      "\r\n",
      "\n",
      "int32\n",
      "          Height  Weight\n",
      "0            161      88\n",
      "1            175      75\n",
      "2            205      70\n",
      "3            181      83\n",
      "4            177      80\n",
      "...          ...     ...\n",
      "99999995     190      86\n",
      "99999996     171      81\n",
      "99999997     182      80\n",
      "99999998     169      80\n",
      "99999999     174      68\n",
      "\n",
      "[100000000 rows x 2 columns]\n",
      "\r\n",
      "\n",
      "int64\n",
      "          Height  Weight\n",
      "0            161      88\n",
      "1            175      75\n",
      "2            205      70\n",
      "3            181      83\n",
      "4            177      80\n",
      "...          ...     ...\n",
      "99999995     190      86\n",
      "99999996     171      81\n",
      "99999997     182      80\n",
      "99999998     169      80\n",
      "99999999     174      68\n",
      "\n",
      "[100000000 rows x 2 columns]\n",
      "\r\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for key,df in dfs.items():\n",
    "    print(key)\n",
    "    print(df)\n",
    "    print('\\r\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f2fbf0",
   "metadata": {},
   "source": [
    "**Answer**: The Height values in the first DataFrame (the one encoded using *int8*) are corrupted. \n",
    "\n",
    "To invetigate, we will check the range of values *int8* can encode. The following code uses the function `np.iinfo()` to do that. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00a63e9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "iinfo(min=-128, max=127, dtype=int8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.iinfo('int8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cba1545",
   "metadata": {},
   "source": [
    "As we can see int8 cannot accomodate to hold numbers larger than 127, and that is why we cannot use it to encode the value of height in centimeters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a163f8",
   "metadata": {},
   "source": [
    "4.\tThe following code performs a computational experiment to see if the runtime of performing big data manipulations changes when our data is encoded in *int8*, *int16*, *int32*, or *int64*. The code attempts to calculate the **Body Mass Index (BMI)** which is a health metric calculated from the height and weight of an individual. The formula for BMI is weight in Kilograms divided by the square of the height in Meters. Run the following code and study its outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f09dc2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        RunTime\n",
      "int8   1.960551\n",
      "int16  2.471621\n",
      "int32  1.801935\n",
      "int64   3.56097\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "exp1_df = pd.DataFrame(\n",
    "    index = dfs.keys(),\n",
    "    columns=['RunTime']\n",
    ")\n",
    "for key in dfs.keys():\n",
    "    wdf = dfs[key]\n",
    "    t0 = time.time()\n",
    "    wdf['BMI'] = wdf.Weight/((wdf.Height/100)**2)\n",
    "    exp1_df.at[key,'RunTime'] = time.time()-t0\n",
    "print(exp1_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f3f48a",
   "metadata": {},
   "source": [
    "5.\tWeren’t you expecting to see an increasing `RunTime` when we move from *int8* to *in64*? However, that’s not what happens when you run the code. What do you think is the reason? If you are having a hard time coming to an answer, study and run the following code, it will give you a hint. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dfd6640",
   "metadata": {},
   "source": [
    "Yes, it is the natural guess that as the data is encoded in a bulkier way, the CPU has to work harder to get it processed. \n",
    "\n",
    "Let's see the hint first before answering why this happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30f24789",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000000 entries, 0 to 99999999\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Dtype  \n",
      "---  ------  -----  \n",
      " 0   Height  int8   \n",
      " 1   Weight  int8   \n",
      " 2   BMI     float64\n",
      "dtypes: float64(1), int8(2)\n",
      "memory usage: 953.7 MB\n",
      "\r\n",
      "--DIVIDE--\r\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000000 entries, 0 to 99999999\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Dtype  \n",
      "---  ------  -----  \n",
      " 0   Height  int16  \n",
      " 1   Weight  int16  \n",
      " 2   BMI     float64\n",
      "dtypes: float64(1), int16(2)\n",
      "memory usage: 1.1 GB\n",
      "\r\n",
      "--DIVIDE--\r\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000000 entries, 0 to 99999999\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Dtype  \n",
      "---  ------  -----  \n",
      " 0   Height  int32  \n",
      " 1   Weight  int32  \n",
      " 2   BMI     float64\n",
      "dtypes: float64(1), int32(2)\n",
      "memory usage: 1.5 GB\n",
      "\r\n",
      "--DIVIDE--\r\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000000 entries, 0 to 99999999\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Dtype  \n",
      "---  ------  -----  \n",
      " 0   Height  int64  \n",
      " 1   Weight  int64  \n",
      " 2   BMI     float64\n",
      "dtypes: float64(1), int64(2)\n",
      "memory usage: 2.2 GB\n",
      "\r\n",
      "--DIVIDE--\r\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for df in dfs.values():\n",
    "    df.info()\n",
    "    print('\\r\\n--DIVIDE--\\r\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093c3997",
   "metadata": {},
   "source": [
    "All of the **BMI** is listed as *float64*. The reason for the unexpected `RunTime` in the previous step is the time it takes for the integer data types to be transformed into *float64*. *int32* will be transformed to *float64* the fastest and that's why the DataFrame with *int32* was quickest to be manipulated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aeff0a4",
   "metadata": {},
   "source": [
    "6.\tThe following code runs another experiment. Once you run the experiment you will see that when we move from int8 to in64 the RunTime also increases. Study the code, and figure out what’s different in this code that matches our expectations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a4728b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        RunTime\n",
      "int8   0.846579\n",
      "int16  0.499681\n",
      "int32  0.757181\n",
      "int64  4.391319\n"
     ]
    }
   ],
   "source": [
    "exp2_df = pd.DataFrame(\n",
    "    index = dfs.keys(),\n",
    "    columns=['RunTime']\n",
    ")\n",
    "for key in dfs.keys():\n",
    "    wdf = dfs[key]\n",
    "    t0 = time.time()\n",
    "    wdf['Some Calculation'] = wdf.Weight+(wdf.Height**2)\n",
    "    exp2_df.at[key,'RunTime'] = time.time()-t0\n",
    "print(exp2_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46259e8f",
   "metadata": {},
   "source": [
    "**Answer**: The difference is that the computation to create the new column `'Some Calculation'` does not require data transformation from integer to float, and that is why what we would expect to see is as the data type becomes heavier the CPU has to work harder will be confirmed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97f5c57",
   "metadata": {},
   "source": [
    "7.\tIf you are having trouble answering the question in the preceding step, running the following code will give you an important hint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "50df8853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000000 entries, 0 to 99999999\n",
      "Data columns (total 4 columns):\n",
      " #   Column            Dtype  \n",
      "---  ------            -----  \n",
      " 0   Height            int8   \n",
      " 1   Weight            int8   \n",
      " 2   BMI               float64\n",
      " 3   Some Calculation  int8   \n",
      "dtypes: float64(1), int8(3)\n",
      "memory usage: 1.0 GB\n",
      "\r\n",
      "--DIVIDE--\r\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000000 entries, 0 to 99999999\n",
      "Data columns (total 4 columns):\n",
      " #   Column            Dtype  \n",
      "---  ------            -----  \n",
      " 0   Height            int16  \n",
      " 1   Weight            int16  \n",
      " 2   BMI               float64\n",
      " 3   Some Calculation  int16  \n",
      "dtypes: float64(1), int16(3)\n",
      "memory usage: 1.3 GB\n",
      "\r\n",
      "--DIVIDE--\r\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000000 entries, 0 to 99999999\n",
      "Data columns (total 4 columns):\n",
      " #   Column            Dtype  \n",
      "---  ------            -----  \n",
      " 0   Height            int32  \n",
      " 1   Weight            int32  \n",
      " 2   BMI               float64\n",
      " 3   Some Calculation  int32  \n",
      "dtypes: float64(1), int32(3)\n",
      "memory usage: 1.9 GB\n",
      "\r\n",
      "--DIVIDE--\r\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000000 entries, 0 to 99999999\n",
      "Data columns (total 4 columns):\n",
      " #   Column            Dtype  \n",
      "---  ------            -----  \n",
      " 0   Height            int64  \n",
      " 1   Weight            int64  \n",
      " 2   BMI               float64\n",
      " 3   Some Calculation  int64  \n",
      "dtypes: float64(1), int64(3)\n",
      "memory usage: 3.0 GB\n",
      "\r\n",
      "--DIVIDE--\r\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for df in dfs.values():\n",
    "    df.info()\n",
    "    print('\\r\\n--DIVIDE--\\r\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421b94bd",
   "metadata": {},
   "source": [
    "**Answer**: We can see that `Some Calculation` has the same data type as the `Height` and `Weight` of the DataFrame, and that is why our expectation matches what happened in the previous step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd3df78",
   "metadata": {},
   "source": [
    "8.\tFrom what you experienced, formulate an answer to the following question: if we are aiming to use the lightest-weight-possible integer data type between *int8*, *int16*, *int32*, and *int64*, how can we make sure that our data will not get corrupted similar to what we experienced in step 2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43172132",
   "metadata": {},
   "source": [
    "**Answer**: We have to check the range that the integer type can accommodate and if we would expect all of the values to be in that range, then we can use that type, otherwise we have to go to the next larger data type."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7922a2f6",
   "metadata": {},
   "source": [
    "\n",
    "9.\tFrom what you experienced, formulate an answer to the following question: in what situations choosing the lightest-weight-possible integer data type will for sure lead to less CPU usage?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4482154d",
   "metadata": {},
   "source": [
    "**Answer**: If only the data does not have to be transformed during the data manipulation then making sure that we are using the lightest-weight-possible integer data will also guarantee less CPU processing as well.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c74235",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
