{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "930341af",
   "metadata": {},
   "source": [
    "# Optimizing the Python Code for Big Data \n",
    "Balancing Coding Complexity against Computational Complexity \n",
    "    \n",
    "    AUTHOR: Dr. Roy Jafari \n",
    "\n",
    "\n",
    "# Chapter 2: Choosing the right data types \n",
    "\n",
    "## Challenge 3: float32 or float64?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf6d3b9",
   "metadata": {},
   "source": [
    "1.\tIn the experiment, we want to run we will compare the RAM and CPU performance of our computer in regard to six DataFrames. We will keep everything the same but two aspects of these dataframes: their number of rows, and their data types. The DataFrames can have one of the following possible number of rows: *1,000,000*, *10,000,000*, or *100,000,000*. Moreover, the values in the DataFrame will either be *float32* or *float64*. The following code creates the dictionary of dictionary `dfs` that will be holding all the DataFrames that we will randomly generate for this experiment. Run the following code and study its output."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2fa19c6",
   "metadata": {},
   "source": [
    "```\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "float_dtypes = ['float32','float64']\n",
    "n_rows = [10**6,10**7,10**8]\n",
    "dfs = {dtype:{n:None for n in n_rows} for dtype in float_dtypes} \n",
    "print(dfs)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cad38e0",
   "metadata": {},
   "source": [
    "2.\tIn the preceding code, were you able to understand the following line?\n",
    "\n",
    "`dfs = {bits:{n:None for n in n_rows} for bits in float_bits}`\n",
    "\n",
    "If yes, just go to the next step, if not Google List Comprehension and learn about it. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f469392",
   "metadata": {},
   "source": [
    "**Answer**: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8405c98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "205b078d",
   "metadata": {},
   "source": [
    "3.\tThe following code generates the corresponding DataFrames for our experiment. We will have six DataFrames with one of the listed data types and the number of rows. Run the following code, and then go to the next step. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c924a23",
   "metadata": {},
   "source": [
    "```\n",
    "import itertools as itt\n",
    "for dtype,n in itt.product(float_dtypes,n_rows):\n",
    "    df = pd.DataFrame(\n",
    "        np.random.random([n,3]),\n",
    "        columns=['RC1','RC2','RC3'],\n",
    "        dtype=dtype\n",
    "        )\n",
    "    dfs[dtype][n] = df\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec46595",
   "metadata": {},
   "source": [
    "4.\tAre you familiar with `itertools`? If yes, just move to step 6. If not, you want to Google it. It is a useful Python Library that will allow you to do various types of iterations. Here, we are just using it to clean up our code. The following code does the same iterations we are creating in the preceding code, twice, once using `itertools` and once with regular for loops. Run the code, and then document your findings. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c57195",
   "metadata": {},
   "source": [
    "```\n",
    "for dtype,n in itt.product(float_dtypes,n_rows):\n",
    "    print(dtype, n)\n",
    "    \n",
    "print('\\r\\n--DIVIDE--\\r\\n')\n",
    "\n",
    "for dtype in float_dtypes:\n",
    "    for n in n_rows:\n",
    "        print(dtype, n)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8f8818",
   "metadata": {},
   "source": [
    "**Answer**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37dd8b84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6c947c83",
   "metadata": {},
   "source": [
    "5.\tThe following code creates `exp_df` which is the DataFrame we will use to record our measurements for this experiment. The measurements we will use are `MemeoryUsage` and `RunTime`. Please pay attention that `exp_df` has multi-level indexing. Run the code, study its output and then go to the next step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea15ecd",
   "metadata": {},
   "source": [
    "```\n",
    "multi_index = pd.MultiIndex.from_product(\n",
    "    [float_dtypes, n_rows],\n",
    "    names= ['Dtype','n_rows']\n",
    ")\n",
    "exp_df = pd.DataFrame(\n",
    "    index = multi_index,\n",
    "    columns= ['MemeoryUsage (KB)','RunTime']\n",
    ")\n",
    "print(exp_df)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3230aa27",
   "metadata": {},
   "source": [
    "6.\tThe following code fills up the first column in `exp_df`; in other words, it grabs the `MemoryUsage` from each of the DataFrames in `dfs` and records them in `exp_df`. Run the code and study its outputs. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef70073",
   "metadata": {},
   "source": [
    "```\n",
    "for dtype,n in itt.product(float_dtypes,n_rows):\n",
    "    wdf = dfs[dtype][n]\n",
    "    usage = wdf.memory_usage().sum()//1000\n",
    "    exp_df.at[(dtype,n),'MemeoryUsage (KB)'] = usage\n",
    "print(exp_df)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07ee7e4",
   "metadata": {},
   "source": [
    "7.\tAfter studying the output of the preceding code, what is your observation regarding the relationship between the number of rows and `MemoryUsage`? What are your observations regarding the relationship between the choice of data types *float32* or *float64* and `MemoryUsage`?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96cc04e3",
   "metadata": {},
   "source": [
    "**Answer**:\n",
    "\n",
    "**what is your observation regarding the relationship between the number of rows and `MemoryUsage`?** \n",
    "\n",
    "**What are your observations regarding the relationship between the choice of data types *float32* or *float64* and `MemoryUsage`?** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae8e489",
   "metadata": {},
   "source": [
    "8.\tThe following code fills up the second column in `exp_df`; in other words, it grabs each of the DataFrames and performs the CPU-intensive task of **Principal Component Analysis (PCA)** on them; the time it takes for the computer to complete the task will be recorded under `RunTime`. Run the code and study its outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f71bc2e",
   "metadata": {},
   "source": [
    "```\n",
    "import time\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA()\n",
    "for dtype,n in itt.product(float_dtypes,n_rows):\n",
    "    t0 = time.time()\n",
    "    wdf = dfs[dtype][n]\n",
    "    pca.fit(wdf)\n",
    "    exp_df.at[(dtype,n),'RunTime'] = time.time()-t0\n",
    "print(exp_df)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dddaef9b",
   "metadata": {},
   "source": [
    "9.\tAfter running the preceding code, you can see the results of our experiment. However, the result might be too overwhelming for you to see, running the following code will create reports and visualizations that will make the pattern easier for you to see. What are your observations?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee8bd99",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "```\n",
    "import matplotlib.pyplot as plt\n",
    "print(exp_df.unstack().RunTime)\n",
    "exp_df.unstack().RunTime.plot.bar()\n",
    "plt.ylabel('time (s)')\n",
    "plt.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a52754f",
   "metadata": {},
   "source": [
    "**Answer**: \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516c1765",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bc475d75",
   "metadata": {},
   "source": [
    "10.\tBased on your experience in this challenge, fill in the blanks in the following sentences. When we have Big Data, more than one million records, it is best to use *float32* instead of *float64* when one or both of the following are correct. 1) we don’t expect our values to go beyond the range [__________, __________]; 2) we won’t need a resolution that is more precise than __________.     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "184b927c",
   "metadata": {},
   "source": [
    "**Answer**: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d1461d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
