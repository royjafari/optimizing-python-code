{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "637d998f",
   "metadata": {},
   "source": [
    "# Optimizing the Python Code for Big Data \n",
    "Balancing Coding Complexity against Computational Complexity \n",
    "\n",
    "    \n",
    "    AUTHOR: Dr. Roy Jafari \n",
    "\n",
    "# Chapter 4: Taking Advantage of Vectorization and Broadcasting (V&B) \n",
    "\n",
    "## Challenge 1: V&B, iterating, applying, or mapping?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7f57ca",
   "metadata": {},
   "source": [
    "In this challenge, we are going to experience the significant difference between the performance of four methods of doing array operations. The four methods are the following.\n",
    "\n",
    "- Iteration\n",
    "- Pandas .apply() funciton \n",
    "- Mapping function\n",
    "- V&B\n",
    "\n",
    "Answer the following questions and do the following tasks.\n",
    "\n",
    "1.\tIn this challenge, we will be using `numpy`, `pandas`, and `matplotlib` modules. So go ahead and import them as the following. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4ac3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8750330",
   "metadata": {},
   "source": [
    "2.\tThe following code defines the function `one_experiment()` which creates a random DataFrame, random_df, which has two randomly generated columns, `C1` and `C2`. The number of rows in `random_df`, `n_rows`, is an input to the function `one_expriment()`. After `random_df` is generated, the function performs the same task of multiplying the values of `C1` with the values of `C2` with four methods, naming `iterate`, `apply`, `map`, and `v&b`, and records the time it takes to get the task done with each method. \n",
    "Study the code to understand exactly what the function `one_experiment()` does and run the code to define the function for your computerâ€™s CPU. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9e7d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_experiment(n_rows):\n",
    "    output, keep={}, []\n",
    "    random_df = pd.DataFrame(\n",
    "        {'C1': np.random.random(n_rows),\n",
    "         'C2': np.random.random(n_rows)}\n",
    "    )\n",
    "    t0= time.time()\n",
    "    for i,row in random_df.iterrows():\n",
    "        keep.append(row.C1*row.C2)\n",
    "    random_df['C3_iterate'] = keep\n",
    "    output['iterate'] = time.time()-t0\n",
    "    t0= time.time()\n",
    "    random_df['C3_map'] = random_df.apply(\n",
    "        lambda r:r.C1*r.C2,\n",
    "        axis=1\n",
    "    )\n",
    "    output['apply'] = time.time()-t0\n",
    "    t0= time.time()\n",
    "    random_df['C3_map'] = list(\n",
    "        map(\n",
    "            lambda x,y:x*y,\n",
    "            random_df.C1,\n",
    "            random_df.C2\n",
    "        )\n",
    "    )\n",
    "    output['map'] = time.time()-t0\n",
    "    t0= time.time()\n",
    "    random_df['C3_map'] =(\n",
    "        random_df.C1 * random_df.C2\n",
    "    ) \n",
    "    output['v&b'] = time.time()-t0\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4041d0ca",
   "metadata": {},
   "source": [
    "3.\tNow that we have the function `one_experiment()` defined, go ahead and give it some use and run it with a few different `n_rows`. Study the outputs of the functions and describe your observations. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f35b2b",
   "metadata": {},
   "source": [
    "**Answer**: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15cd6c5e-f510-490c-b4cb-6fbc4105d82a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "24b1d5dc",
   "metadata": {},
   "source": [
    "4.\tThe following function creates the function `experiments()` that expand the capability of the function `one_experiment()`. While the function `one_experiment()` only takes in `n_rows`, the function experiment also takes in `n_repeats`. The input `n_repeats` is the number of times that the function `one_experiment()` is repeated and the average time it takes for each method to complete the task is recorded and outputted. We added `n_repeats` because if we compare the methods only with just a one-time experiment the comparisons are not as reliable. Study the code and understand what exactly it does, and then run the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbefd625",
   "metadata": {},
   "outputs": [],
   "source": [
    "method_list = ['iterate','apply','map','v&b']\n",
    "def experiments(n_rows,n_repeat):\n",
    "    output = {m:0 for m in method_list}\n",
    "    for _ in range(n_repeat):\n",
    "        result = one_experiment(n_rows)\n",
    "        output = {m:result[m]+output[m] \n",
    "                  for m in method_list}\n",
    "    return {m:round(output[m]/n_repeat,5)\n",
    "            for m in method_list}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f527f2",
   "metadata": {},
   "source": [
    "5.\tNow that we have the function `experiments()` defined, go ahead and give it some use and run it with a few different `n_rows` and `n_repeats`. For instance, you might want to run `experiments(100,5)` or `experiments(1000,10)`. Study the outputs of the functions and describe your observations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb43e2d",
   "metadata": {},
   "source": [
    "**Answer**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d23d86-1bea-457d-b6c8-e02ac2000ab4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8acbf3c5",
   "metadata": {},
   "source": [
    "6.\tNow we want to set up to do a systematic experiment to compare the four methods we are studying. The following code creates `result_df` which we will later use to record and study the results of our experiments. The index of `result_df` is the `n_rows` we will be passing to `experiments()`. Run the code and study its printout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d90e28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_options = [10**i for i in range(2,6)]\n",
    "result_df = pd.DataFrame(index = exp_options,\n",
    "                         columns = method_list)\n",
    "print(result_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97a8eb5",
   "metadata": {},
   "source": [
    "7.\tThe following code simply runs the function `experiment()` for each row if `result_df` and records its output into `result_df`. Pay attention that we are also passing 5 as `n_repeats` to experiment. run the code and study its output. Pay attention the code might take a few minutes to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024434de",
   "metadata": {},
   "outputs": [],
   "source": [
    "for o in exp_options:\n",
    "    result_df.loc[o] = experiments(o,5)\n",
    "print(result_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2547617f",
   "metadata": {},
   "source": [
    "8.\tNow we can use the wonderful matplotlib module to visualize our experiment. Run the following code, study the line plot it creates and describe your observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a609e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in method_list:\n",
    "    result_df[m].plot(logx=True)\n",
    "plt.xlabel('n_rows')\n",
    "plt.ylabel('seconds')\n",
    "plt.legend()\n",
    "plt.savefig('images/challenge1_8.png', dpi=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6bf09b7",
   "metadata": {},
   "source": [
    "**Answer**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21bd6379-efe7-4eba-b771-cc0c1a9178e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7c7c5011",
   "metadata": {},
   "source": [
    "9.\tFrom your observation in the plot that you created in step 8, answer the following questions: 1) at what `n_rows` do we start seeing a significant difference between the methods `iterate` and `apply`? 2) at what `n_rows` do we start seeing a significant difference between the method `apply` and `map`? 3) at what `n_rows` do we start seeing a significant difference between the method `map` and `v&b`? Pay attention, the correct answer to some of the quesitons might be that the visual cannot help you answer the question."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3ae150",
   "metadata": {},
   "source": [
    "**Answer**:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a72b64e-d56f-47ba-9929-135b20053239",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ef34ec39",
   "metadata": {},
   "source": [
    "10.\tFor the questions that you were not able to answer, in step 9, design, code, and perform experiments and visualize its results so we can answer those questions. Answer the question(s) after completing the described experiments. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc29e04",
   "metadata": {},
   "source": [
    "**Answer**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12443df9-1c3e-406e-a687-15abed344f53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
